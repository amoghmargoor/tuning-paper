\section{Iterative Method} \label{section:iter}
In the first approach, we actually execute each query multiple times with different configuration parameters to determine the optimal set of parameters. For each candidate set of configuration parameters, the query is run and the target metric, such as total resource usage, is measured. By comparing the metrics across different runs with different configuration parameters, we can determine a good set of parameters to use. 

\subsection{Algorithm}
The overall algorithm is listed in Figure~\ref{alg:iterativesearch} and is fairly straightforward. It starts with the default value for each configuration parameter (Line 1). It then iterates over the parameters and for each parameter it explores a range of values from low to high, varying it with a minimum step size (Lines 2--6). It runs the query with the chosen parameter values and measures the metric (such as running time or utilization). It finds the value for which the metric is optimized and fixes the value of the parameter to that value before moving on the next parameter (lines 7--12). Finally, it outputs the set of good parameter values $V$ that are discovered in the process.
\renewcommand{\algorithmicrequire}{\textbf{Input:}}
\renewcommand{\algorithmicensure}{\textbf{Output:}}
\renewcommand{\algorithmiccomment}[1]{// #1}
\begin{algorithm}[h]
	\caption{\bf \textit{Iterative Search}}
	\label{alg:iterativesearch}
	\begin{algorithmic}[1]
		%\vspace{1.3em}
		%\small
		\footnotesize
		\REQUIRE Set $\mathcal{P}$ = $\{p_1, p_2 \ldots p_n\}$ of parameters to be determined, the metric $m$ to be optimized, the query $Q$
		\ENSURE The values for parameters in $\mathcal{P}$ that optimize $m$
		\STATE Let $V$ = $\{v_1, v_2, \ldots v_n\}$ = $\{p_1^d, p_2^d, \ldots p_n^d\}$
		\COMMENT {$p_i^l$, $p_i^d$ and $p_i^h$ denote the low value, default value and high value for parameter $p_i$}		
		\FOR {Param $p_i$ in $\mathcal{P}$}
			\STATE Reset $m_{best}$
			\FOR {Value $v$ from $p_i^l$ to $p_i^h$ in steps of $p_i^s$}
				\STATE Replace $v_i$ by $v$ in $V$
				\STATE Run $Q$ with parameter setting $V$ and measure the metric $m$
				\IF {$m$ is better than $m_{best}$}
					\STATE $m_{best} = m$
					\STATE $v_{best} = v$
				\ENDIF
			\ENDFOR
			\STATE Replace $v_i$ by $v_{best}$ in $V$ \COMMENT{Best value for parameter $p_i$ is found and used in further search}			
		\ENDFOR
		\RETURN Output $V$
    \end{algorithmic}
\end{algorithm}
  
\subsection{Results}
We evaluated the effectiveness and practicality of the iterative method by running experiments on both synthetic and real workloads. The experiments were carried out for a HIVE on MR engine. The results demonstrated the importance of optimizing the configuration parameters, but at the same time motivated us to explore the model based method instead of the iterative method. We thus present the results here before moving on describing the model based approach.

\subsubsection*{Synthetic Workload}
For synthetic workload, we used the TPC DS dataset (scale 1000) and queries. Each query had to be run a number of times to discover a good set of configuration parameters. To keep the time for the experiments reasonable, we had to use a somewhat small dataset. The average data read by each query was of the order of 20 to 40 GB. The experiments were run on a 4 node cluster on AWS with machine type r3.xlarge. The metric to be optimized was the total resource utilization as (Formula~\ref{}) and parameters whose values are to be determined are the ones mentioned earlier in Table~\ref{}. For each query, we compare the best and worst configuration discovered with the default one in terms of the resource utilization. The results are shown in Figure~\ref{fig:iterativetpcds}. It plots the ratios of the resource usage of minimum to default, maximum to default and maximum to minimum. The min corresponds to the best configuration discovered and max corresponds to the worst configuration among the ones tried out. The graph shows that the min to default ratio varies from 0.18 to 0.73, which indicates that the iterative search leads to a configuration that can save upto 82\% in resource usage over the default configuration. The ratio of max to default is mostly close to 1 and in some cases goes upto 1.80. This indicates that in many cases, the default configuration itself was the worst one (same as max). This is due to the fact that the default split size was 128 MB, leading to a large number of mappers, each processing small amount of data. Since there is some overhead (5-10s) in starting the JVM for each mapper, the startup time becomes significant percentage of the total mapper time if the mapper itself takes very less time to process the data. As a result, the overall query time suffers and resource utilization increases. This suggests that a different default with a larger split size would be more appropriate. Finally, the ratio of max to the min varies from 1.47 to 5.41, indicating that the configuration parameters do make a significant difference in query execution. 
\begin{figure}[h]
	\includegraphics[width=\linewidth]{fig/tpcds-iterative.png}
	%\vspace*{-15pt}
	\caption{Iterative algorithm on TPC DS}
	\label{fig:iterativetpcds}
\end{figure}

\subsubsection*{Real Workloads}
We evaluated the iterative method over real customer data and queries. The workload consisted of three Hive queries running on Hadoop2 MR. These queries were very large and complex and part of their analytics workflow. The input data size was about 400 GB for two of the queries and 200 GB for the third query. The cluster consisted of a r3.2xlarge master node and 30 slave nodes of type r3.8xlarge on AWS Cloud. Figure~\ref{fig:iterativelyft} shows the percentage savings in the cost of the three queries with the configuration discovered by the iterative algorithm, compared to the cost with the configuration that the customer was using in production. The results show that the iterative algorithm was able to achieve significant savings upto 77\% even for production workloads, indicating that many production workloads are not fully optimized. However, the iterative algorithm took over 50 hours and cost \$5000 since the cluster was quite large with powerful machines. 
\begin{figure}[h]
	\includegraphics[width=\linewidth]{fig/lyft.png}
	%\vspace*{-15pt}
	\caption{Iterative algorithm on real workload}
	\label{fig:iterativelyft}
\end{figure}

\subsubsection*{Discussion}
The results on synthetic and real datasets show that finding good configuration parameters can lead to significant savings in query costs. The iterative algorithm is able to discover good configuration parameters in a small number of iterations (usually around 10-15 iterations). However, there are some practical limitations as listed below:
\begin{itemize}
	\item The dollar cost of the optimization process can be significant as seen in the real workload. In this case, the customer had 1000 more queries. It may be possible to make the search more efficient and reduce the number of iterations. Since  customers have 100s or 1000s of queries, even 10 or 50 fold reduction is not sufficient to make the approach economical.
	\item For ETL queries, the approach requires shadow clusters and queries. The queries had to be reviewed multiple times to make sure production clusters and tables were not affected. The cost in terms of man-hours is also exorbitant. 	
\end{itemize} 
To address these concerns, we propose a cost model based optimization approach next that does not require multiple executions of the query with different parameters.
