\documentclass[conference]{IEEEtran}
\IEEEoverridecommandlockouts
% The preceding line is only needed to identify funding in the first footnote. If that is unneeded, please comment it out.
\usepackage{cite}
\usepackage{amsmath,amssymb,amsfonts}
\usepackage{algorithmic}
\usepackage{algorithm}
\usepackage{graphicx}
\usepackage{textcomp}
\usepackage{courier}
\usepackage{xcolor}
\def\BibTeX{{\rm B\kern-.05em{\sc i\kern-.025em b}\kern-.08em
    T\kern-.1667em\lower.7ex\hbox{E}\kern-.125emX}}
\begin{document}

\title{Improving Join Reordering for Large Scale Distributed Computing\\
}

\author{\IEEEauthorblockN{Amogh Margoor}
\IEEEauthorblockA{\textit{Qubole Inc.} \\
Santa Clara, US}
\and
\IEEEauthorblockN{ Mayur Bhosale}
\IEEEauthorblockA{\textit{Qubole Inc.} \\
Bangalore, India}
}

\maketitle

\begin{abstract}
 SQL Join is one of the most commonly used operators for workloads running upon SQL Engines built for Big Data like Apache Spark SQL, Apache Hive and Presto. As Joins on Big Data can be expensive, Join optimizations can significantly improve the efficiency and performance of it's workloads. In this work, we would address the problem of finding optimal order for SQL Joins, which is a well researched NP-Hard problem for traditional workloads but not for Big Data workloads. Traditional Cost Based Optimization in Query processing, including Join Reordering algorithms are not effective on Big Data due to lack of statistics. Statistics are mostly absent in Big Data as they are expensive to compute and needs frequent recompute due to velocity of data change. Hence, ensuring optimal order of Joins for Big Data is still largely a manual process done via trial and error.

We would like to propose a novel greedy algorithm for Join Reordering which can work in the absence of statistics. Proposed technique is of linear complexity in terms of number of joins. We have observed that on TPC-DS benchmarks it can reorder 38 queries and improve query performance upto 85\%.
\end{abstract}

\begin{IEEEkeywords}
SQL on Big Data, Query Processing, Join Order, Data Management Systems
\end{IEEEkeywords}

\section{Introduction}
Massive analytics on Big Data using Large Scale Data processing are increasingly being used for business decisions. SQL Engines like Apache Spark~\cite{b9}, Apache Hive~\cite{b10} and Presto have been built for Big Data to address these needs. Such Engines have adapted many traditional DBMS relational techniques in this paradigm, making SQL operators like Join quite popular and common for Big Data Processing. For instance, on Qubole Data Service we see around 4 million joins getting processed every month through Apache Spark. Hence, optimizing Joins can improve the efficiency and performance of such workloads significantly. Finding optimal order of Joins is a very important Join optimization that can be extremely beneficial and hence, a well studied NP-Hard problem in traditional DBMS world.

Like in traditional systems, SQL Engines on Big Data also have Cost-Based Optimizer that can find the optimal join order using Dynamic Programming based algorithms \cite{b1}. However, availability of the extensive statistics like column statistics~\cite{b11} are pre-requisite for these traditional approaches. For instance, Apache Spark or Presto's Join Ordering will not work without the column statistics. In general, such statistics are absent for Big Data workload rendering these techniques ineffective. The volume of Big Data runs in TBs and PBs nowadays, associated with high velocity of change. Under such circumstances  computing statistics and maintaining it for new data changes can be expensive for Users, hence almost never present.

An alternative to Cost Based approach to figure out optimal Join Order would be Adaptive query processing~\cite{b12}. Adaptive query processing can use runtime feedback to change the query plan being executed for better performance and efficiency. So even if statistics are not available, if such framework can compute statistics during runtime, it can be used to find optimal Join Order.
Firstly, such sophisticated framework is not present in many of the existing SQL engines for Big Data. Only Apache Spark has introduced support for it currently.  Secondly, 
even on Apache Spark modifying Adaptive query processing  do not provide column level stats at runtime from it's Query Stage which can be used to perform Join Reordering. Ensuring such elaborate statistics during runtime and waiting for all the Table Scan to finish for such statistics before starting any join can be detrimental to the performance of the query.

We analyzed the customer workloads at Qubole and couple of patterns emerged:
\begin{enumerate}
\item Statistics: Statistics were absent for almost all of the workloads. But  during planning stage, on-the-fly table sizes are computed by Apache Spark and Apache Hive if table sizes are not present. It is computed by listing the files under the table to obtain file metadata (with size information) and adding up the sizes of the each file. This is done to ensure when joining with small tables, Broadcast Joins ~\cite{b13} on Spark or Map-Side Joins ~\cite{b10} on Hive can be performed which would make Joins faster. This is an important optimization which we briefly describe in Section ~\ref{subsubsec:sparkjoin}. These table sizes computation on the fly are the reason why among 4 million joins processed per month by Apache Spark on Qubole Data Service, 44 \% of them are Broadcast Joins as shown in Table ~\ref{tab:stats}.
\item Fact-Dimension Join: Another important pattern that emerged was that most of the queries with joins either on Snowflake schema or Star Schema will have Fact to Dimension table joins. Lot of queries with multi-table joins have 1 or multiple Fact tables involved in Join with other smaller dimension tables. That is the reason we see lot of Broadcast Joins (almost 44 \% of Joins according to Table ~\ref{tab:stats}) in Big Data workloads i.e., lot of small tables being used on one side of the Join.
\end{enumerate}

Based on the patterns above, in this paper we will present our technique for Join ordering using Table Sizes computed on-the-fly. Using the above patterns we devised a greedy technique for Join Reordering. At high level it performs two main steps:
\begin{enumerate}
\item Identify Dominant Fact table in a query i.e., Fact table involved in more than half number of Joins in the query. 
\item Perform Reordering of the Filtered Dimension tables involved in join with the Dominant Table.
\end{enumerate}

Apart from the fact that this technique can work in absence of Statistics, it is also executes in linear time i.e., linear to the number of Joins in the Query. It is simple enough to be implemented as an Optimizer rule for the popular SQL engines on Big Data.  

We have implemented this technique in Qubole's distribution of Apache Spark as a Catalyst Rule. We have found it to be effective both on Customer workloads and TPC-DS benchmarks inspite of being simple to implement and reason about. When evaluated on TPC-DS benchmark at 100 scale, we saw 38 queries being Join reordered among 100 queries. Out of all reordered queries, 71.1\% reordered queries showed up to 30\% improvement, 15.8\% queries showed between 30 to 60\% improvement and 13.2\% queries showed greater than 60\% improvement.

In the following Section ~\ref{sec:background} we will give a background on Joins, Statistics and Adaptive Execution in Big Data. Then we will propose our technique and algorithm in Section~\ref{sec:jo}. We will also present experimental evaluation of the algorithm in Section~\ref{sec:exp-evaluation}. In the following Section ~\ref{sec:rel_work}, we will discuss the existing work done in academia for Join Reordering and their relevance to our problem statement.

\section{Background}\label{sec:background}

Customers using Qubole Data Service processes 4 million joins per month using just Apache Spark, making it one of the most commonly used SQL operators. Table \ref{tab:stats} specifies some of the Join metrics we collected for a month on Qubole's offering of Apache Spark. We see around 51\% of joins being INNER JOIN and around 55\% of all Joins using Merge Sort Join algorithm. Due to the frequency and the complexity of Joins, Join Order and Join Strategy are two important decision to be made by Optimizers of SQL Big Data Engines. Optimizers of these Big Data engines like Apache Spark uses traditional Dynamic Programming based algorithms \cite{b1} dependent on column level statistics. Such extensive statistics are absent for Big Data workloads as they are expensive to compute and maintain. Due to unavailability of statistics, traditional approaches for Join reordering will not work. Hence, critical operation of ensuring optimal order of Joins are left to analyst and still is largely a manual effort which is error prone. We would like to propose technique which can work on just the table sizes which can be computed during planning stage even if absent in a cheap manner.


\begin{table}[h]
\begin{center}
\begin{tabular}{ |c|c| }
 \hline \\
Joins Processed & 3.9 million \\ \hline \\
Most common Join Type & INNER JOIN - 51\%  \\  \hline \\
Second most common Join Type &  LEFT OUTER JOIN - 31\%\\ \hline  \\
Most common Join algorithm & SortMergeJoin - 55\%\\ \hline \\
Second most common Join algorithm & BroadcastHashJoin - 44\%\\
 \hline
\end{tabular}
\label{tab:stats}
\end{center}
\caption{Join metrics collected over 1 month for Apache Spark in Qubole}
\end{table}

\input{why_jo}
\input{current_state_in_bigdata}

In above, subsection we clearly saw why traditional approaches like Cost Based Optimizations and Adaptive Execution not work well for finding optimal Join Order in Big Data. Hence, in this paper we will present a novel greedy approach for Join Reordering which can work without expensive statistics for Big Data Systems.

\input{jo}
\input{experimental_evaluation}
\input{literature_survey}
\section*{Acknowledgment}

\begin{thebibliography}{00}
\bibitem{b1} Selinger, P. Griffiths, M. M., Astrahan, D. D., Chamberlin, R. A., Lorie, and T. G., Price. ``Access Path Selection in a Relational Database Management System.`` . In Proceedings of the 1979 ACM SIGMOD International Conference on Management of Data (pp. 23–34). Association for Computing Machinery, 1979.
\bibitem{b2} Amogh Margoor, Rajat Venkatesh. ``SQL Join Optimizations in Qubole Presto,``
https://medium.com/qubole-engineering/sql-join-optimizations-in-qubole-presto-3ced3dc75275, unpublished
\bibitem{b3} Guido Moerkotte and Thomas Neumann. 2006. ``Analysis of Two Existing and One New Dynamic Programming Algorithm for the Generation of Optimal Bushy Join Trees without Cross Products.`` In Proceedings of the 32nd International Conference on Very Large Data Bases, Seoul, Korea, September 12-15, 2006. 930–941.
\bibitem{b4} A. Swami ``Optimization of large join queries: combining heuristics and
combinatorial techniques.`` SIGMOD Record, vol. 18, no. 2, 1989.
\bibitem{b5} L. Fegaras ``A new heuristic for optimizing large queries in DEXA ’98``. Proceedings of the 9th International Conference on Database and Expert Systems Applications, 1998.
\bibitem{b6} N. Bruno, C. Galindo-Legaria and M. Joshi ``Polynomial Heuristics for Query Optimization``. 2010 IEEE 26th International Conference on Data Engineering (ICDE 2010), Long Beach, CA, 2010, pp. 589-600, doi: 10.1109/ICDE.2010.5447916.
\bibitem{b7} Li, Quanzhong and Shao, Minglong and Markl, Volker and Beyer, Kevin and Colby, Latha and Lohman, Guy. (2007)  ``Polynomial heuristics for query optimization,`` Proceedings - International Conference on Data Engineering. 26-35. 10.1109/ICDE.2007.367848.
\bibitem{b8} Li, Youfu and Li, Mingda and Ding, Ling and Interlandi, Matteo. (2018)  `` RIOS: Runtime Integrated Optimizer for Spark`` 275-287. 10.1145/3267809.3267814.
\bibitem{b9} M. Zaharia, M. Chowdhury, M.J. Franklin, S. Shenker, I. Stoica
``Spark: Cluster computing with working sets`` Proceedings of the 2Nd USENIX Conference on Hot Topics in Cloud Computing, HotCloud’10, USENIX Association, Berkeley, CA, USA (2010), p. 10 http://dl.acm.org/citation.cfm?id=1863103.1863113
\bibitem{b10} Apache Hive. http://hadoop.apache.org/hive.
\bibitem{b11} The Internals of Spark SQL. https://jaceklaskowski.gitbooks.io/mastering-spark-sql/content/spark-sql-ColumnStat.html
\bibitem{b12} Avnur R. and Hellerstein J.M. Eddies: ``continuously adaptive query processing.`` In Proc. ACM SIGMOD Int. Conf. on Management of Data, pp. 261–272.2000
\bibitem{b13} Armbrust, M., Reynold Xin, Cheng Lian, Yin Huai, Davies Liu, Joseph K. Bradley, X. Meng, Tomer Kaftan, M. Franklin, A. Ghodsi and M. Zaharia. ``Spark SQL: Relational Data Processing in Spark.`` SIGMOD '15 (2015)
\end{thebibliography}
\end{document}
